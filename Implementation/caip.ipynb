{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.fft as fft\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels Mapping: {'Impeller (3.0BAR)': 0, 'Mechanical seal Hole (3BAR)': 1, 'Mechanical seal Scratch (3.0BAR)': 2, 'Normal (3BAR)': 3}\n"
     ]
    }
   ],
   "source": [
    "# Define dataset path\n",
    "dataset_path = \"E:/CP Dataset/cwt\"  # Change to your actual path\n",
    "\n",
    "# Define image size (for ResNet-18 input)\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Define categories (classes)\n",
    "categories = [\"Impeller (3.0BAR)\", \"Mechanical seal Hole (3BAR)\", \"Mechanical seal Scratch (3.0BAR)\", \"Normal (3BAR)\"]\n",
    "class_labels = {category: i for i, category in enumerate(categories)}  # Map class names to labels\n",
    "\n",
    "# Print class labels\n",
    "print(\"Class Labels Mapping:\", class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images Loaded: 1247\n",
      "Example Image Path: E:/CP Dataset/cwt\\Impeller (3.0BAR)\\0.png\n",
      "Corresponding Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Lists to store image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each category folder and load images\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(dataset_path, category)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".png\"):  # Ensure only images are loaded\n",
    "            image_paths.append(os.path.join(folder_path, file))\n",
    "            labels.append(class_labels[category])\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Total Images Loaded: {len(image_paths)}\")\n",
    "print(f\"Example Image Path: {image_paths[0]}\")\n",
    "print(f\"Corresponding Label: {labels[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images: 872\n",
      "Testing Images: 375\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train (70%) and test (30%)\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Training Images: {len(train_paths)}\")\n",
    "print(f\"Testing Images: {len(test_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image transformations defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define image transformations for training (including data augmentation)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  # Resize to match ResNet-18 input\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images\n",
    "    transforms.RandomRotation(15),  # Random rotation for generalization\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "# Define image transformations for testing (no augmentation)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  # Resize to match ResNet-18 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "print(\"Image transformations defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Dataset Class Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "class CWDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)  # Load grayscale image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # Convert to RGB format\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Print success message\n",
    "print(\"Custom Dataset Class Created Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batches: 28 | Testing Batches: 12\n"
     ]
    }
   ],
   "source": [
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CWDataset(train_paths, train_labels, transform=transform_train)\n",
    "test_dataset = CWDataset(test_paths, test_labels, transform=transform_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Print success message\n",
    "print(f\"Training Batches: {len(train_loader)} | Testing Batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCAM (Spatial & Channel Attention Module) implemented successfully!\n"
     ]
    }
   ],
   "source": [
    "class SCAM(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SCAM, self).__init__()\n",
    "\n",
    "        # Channel Attention\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // 16)\n",
    "        self.fc2 = nn.Linear(in_channels // 16, in_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Spatial Attention\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=7, padding=3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, channels, _, _ = x.size()\n",
    "\n",
    "        # Channel Attention\n",
    "        avg_out = self.global_avg_pool(x).view(batch, channels)\n",
    "        max_out = self.global_max_pool(x).view(batch, channels)\n",
    "        avg_out = F.relu(self.fc1(avg_out))\n",
    "        max_out = F.relu(self.fc1(max_out))\n",
    "        channel_weight = self.sigmoid(self.fc2(avg_out + max_out)).view(batch, channels, 1, 1)\n",
    "        x = x * channel_weight\n",
    "\n",
    "        # Spatial Attention\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        spatial_weight = self.sigmoid(self.conv1(torch.cat([avg_out, max_out], dim=1)))\n",
    "        x = x * spatial_weight\n",
    "\n",
    "        return x\n",
    "\n",
    "# Print success message\n",
    "print(\"SCAM (Spatial & Channel Attention Module) implemented successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT Feature Enhancement implemented successfully!\n"
     ]
    }
   ],
   "source": [
    "class FFTFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFTFeatureExtractor, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert spatial image features to frequency domain\n",
    "        fft_features = torch.fft.fft2(x)  # Compute 2D FFT\n",
    "        fft_features = torch.abs(fft_features)  # Get magnitude spectrum\n",
    "        fft_features = torch.log1p(fft_features)  # Apply log transform to enhance visualization\n",
    "        \n",
    "        return fft_features\n",
    "\n",
    "# Print success message\n",
    "print(\"FFT Feature Enhancement implemented successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnhancedResNet18(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      "  (scam1): SCAM(\n",
      "    (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (global_max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "    (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
      "    (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  )\n",
      "  (fft_module): FFTFeatureExtractor()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EnhancedResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EnhancedResNet18, self).__init__()\n",
    "\n",
    "        # Load Pretrained ResNet-18 Model\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "        # Modify the first layer to accept 6 channels (RGB + FFT)\n",
    "        self.model.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Integrate Attention & FFT Modules\n",
    "        self.scam1 = SCAM(64)  # Attention after first layer\n",
    "        self.fft_module = FFTFeatureExtractor()  # FFT before passing to ResNet\n",
    "\n",
    "        # Modify Fully Connected Layer for 4-class classification\n",
    "        self.model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Dropout for better generalization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract frequency features using FFT\n",
    "        fft_features = self.fft_module(x)\n",
    "\n",
    "        # Concatenate spatial and frequency domain features (6 channels)\n",
    "        x = torch.cat([x, fft_features], dim=1)\n",
    "\n",
    "        # Pass through ResNet first layer\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        # Apply Attention after first convolutional block\n",
    "        x = self.scam1(x)\n",
    "\n",
    "        # Pass through the rest of ResNet-18 layers\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = self.model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Fully Connected Layer with Dropout\n",
    "        x = self.dropout(x)\n",
    "        x = self.model.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EnhancedResNet18(num_classes=4).to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function and optimizer initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define Loss Function (Cross Entropy for Classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define Optimizer (Adam with L2 Regularization)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "\n",
    "# Print success message\n",
    "print(\"Loss function and optimizer initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:30<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 24.2642, Accuracy: 59.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 12.5304, Accuracy: 76.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 11.3707, Accuracy: 79.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:32<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 10.6456, Accuracy: 80.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 8.2484, Accuracy: 86.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Loss: 8.8379, Accuracy: 84.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Loss: 9.4515, Accuracy: 82.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Loss: 8.3780, Accuracy: 89.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:26<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Loss: 7.1518, Accuracy: 88.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:34<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 5.9650, Accuracy: 90.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Loss: 5.0963, Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Loss: 4.6055, Accuracy: 93.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Loss: 8.6511, Accuracy: 88.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Loss: 6.8292, Accuracy: 89.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Loss: 5.1814, Accuracy: 90.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Loss: 4.5507, Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Loss: 5.0822, Accuracy: 92.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Loss: 5.1928, Accuracy: 91.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Loss: 5.1425, Accuracy: 92.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Loss: 5.1504, Accuracy: 92.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Loss: 4.7241, Accuracy: 93.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Loss: 4.0276, Accuracy: 94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Loss: 5.2477, Accuracy: 92.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Loss: 4.7678, Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Loss: 3.7442, Accuracy: 94.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Loss: 3.8297, Accuracy: 94.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Loss: 3.4993, Accuracy: 95.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Loss: 3.5238, Accuracy: 95.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Loss: 4.1577, Accuracy: 93.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 4.3731, Accuracy: 94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "import torch.nn.functional as F  # Fix missing F import\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Start Training\n",
    "train(model, train_loader, criterion, optimizer, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader reinitialized with num_workers=0 to prevent crashes.\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders (Fixing worker issue)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"DataLoader reinitialized with num_workers=0 to prevent crashes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.20%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Function\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradients needed during evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWA Epoch [1/5], Loss: 4.6271, Accuracy: 92.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:29<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWA Epoch [2/5], Loss: 4.4096, Accuracy: 94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:30<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWA Epoch [3/5], Loss: 4.7796, Accuracy: 92.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:34<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWA Epoch [4/5], Loss: 4.5463, Accuracy: 92.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:33<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWA Epoch [5/5], Loss: 4.4280, Accuracy: 92.89%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m train_swa(swa_model, train_loader, criterion, optimizer, swa_scheduler, epochs_swa)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Update model weights to averaged SWA weights\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswa_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_bn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswa_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\swa_utils.py:335\u001b[0m, in \u001b[0;36mupdate_bn\u001b[1;34m(loader, model, device)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 335\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bn_module \u001b[38;5;129;01min\u001b[39;00m momenta\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    338\u001b[0m     bn_module\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m=\u001b[39m momenta[bn_module]\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\swa_utils.py:219\u001b[0m, in \u001b[0;36mAveragedModel.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m, in \u001b[0;36mEnhancedResNet18.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, fft_features], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Pass through ResNet first layer\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "# Convert to SWA model\n",
    "swa_model = AveragedModel(model)\n",
    "\n",
    "# Define SWA learning rate scheduler correctly\n",
    "swa_scheduler = SWALR(optimizer, swa_lr=0.0005, anneal_strategy=\"cos\")\n",
    "\n",
    "# Fine-Tune for last 5 epochs using SWA\n",
    "epochs_swa = 5\n",
    "\n",
    "def train_swa(model, train_loader, criterion, optimizer, swa_scheduler, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        swa_scheduler.step()  # Corrected scheduler step\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"SWA Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Train with SWA\n",
    "train_swa(swa_model, train_loader, criterion, optimizer, swa_scheduler, epochs_swa)\n",
    "\n",
    "# Update model weights to averaged SWA weights\n",
    "torch.optim.swa_utils.update_bn(train_loader, swa_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm statistics updated successfully for SWA Model!\n"
     ]
    }
   ],
   "source": [
    "# Fix SWA BatchNorm Update by ensuring device compatibility\n",
    "def update_bn_fixed(loader, model):\n",
    "    model.train()  # Set to training mode\n",
    "\n",
    "    # Ensure model is on the correct device\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for images, _ in loader:\n",
    "        images = images.to(device)  # Move images to model's device\n",
    "        model(images)  # Forward pass to update batch norm\n",
    "\n",
    "# Run the fixed BN update\n",
    "update_bn_fixed(train_loader, swa_model)\n",
    "\n",
    "print(\"BatchNorm statistics updated successfully for SWA Model!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the SWA model\n",
    "evaluate(swa_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:42<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup Epoch [1/5], Loss: 33.1033, Accuracy: 74.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:37<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup Epoch [2/5], Loss: 30.7357, Accuracy: 75.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:37<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup Epoch [3/5], Loss: 32.2681, Accuracy: 77.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:37<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup Epoch [4/5], Loss: 26.1798, Accuracy: 80.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:37<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup Epoch [5/5], Loss: 33.0553, Accuracy: 74.90%\n",
      "Test Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to apply Mixup\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# Modified Training Loop with Mixup\n",
    "def train_with_mixup(model, train_loader, criterion, optimizer, epochs=5, alpha=0.4):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Apply Mixup\n",
    "            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute Mixup Loss\n",
    "            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (lam * (predicted == labels_a).sum().item() + (1 - lam) * (predicted == labels_b).sum().item())\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Mixup Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Fine-tune with Mixup for 5 epochs\n",
    "train_with_mixup(swa_model, train_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "# Evaluate Again After Mixup Fine-Tuning\n",
    "evaluate(swa_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:31<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutMix Epoch [1/5], Loss: 91.2158, Accuracy: 58.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:29<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutMix Epoch [2/5], Loss: 96.8218, Accuracy: 57.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:29<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutMix Epoch [3/5], Loss: 98.5193, Accuracy: 56.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:29<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutMix Epoch [4/5], Loss: 98.7856, Accuracy: 55.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:29<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CutMix Epoch [5/5], Loss: 95.2226, Accuracy: 56.95%\n",
      "Test Accuracy: 97.60%\n"
     ]
    }
   ],
   "source": [
    "# Function to apply CutMix augmentation\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    # Generate CutMix bounding box\n",
    "    W, H = x.size()[2], x.size()[3]\n",
    "    r_x = np.random.randint(W)\n",
    "    r_y = np.random.randint(H)\n",
    "    r_w = np.random.randint(W // 2)\n",
    "    r_h = np.random.randint(H // 2)\n",
    "\n",
    "    # Apply CutMix\n",
    "    x[:, :, r_x:r_x + r_w, r_y:r_y + r_h] = x[index, :, r_x:r_x + r_w, r_y:r_y + r_h]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "# Modified Training Loop with CutMix\n",
    "def train_with_cutmix(model, train_loader, criterion, optimizer, epochs=5, alpha=1.0):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Apply CutMix\n",
    "            images, labels_a, labels_b, lam = cutmix_data(images, labels, alpha)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute CutMix Loss\n",
    "            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (lam * (predicted == labels_a).sum().item() + (1 - lam) * (predicted == labels_b).sum().item())\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"CutMix Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Fine-tune with CutMix for 5 epochs\n",
    "train_with_cutmix(swa_model, train_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "# Evaluate Again After CutMix Fine-Tuning\n",
    "evaluate(swa_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with TTA: 62.13%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Function for Test-Time Augmentation (TTA)\n",
    "def evaluate_tta(model, test_loader, num_augments=5):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs_list = []\n",
    "            for _ in range(num_augments):\n",
    "                aug_images = images.clone()\n",
    "                \n",
    "                # Apply random transformations for TTA\n",
    "                for i in range(images.shape[0]):\n",
    "                    if np.random.rand() > 0.5:\n",
    "                        aug_images[i] = TF.hflip(images[i])  # Horizontal Flip\n",
    "                    if np.random.rand() > 0.5:\n",
    "                        aug_images[i] = TF.vflip(images[i])  # Vertical Flip\n",
    "                    if np.random.rand() > 0.5:\n",
    "                        aug_images[i] = TF.adjust_brightness(images[i], np.random.uniform(0.8, 1.2))  # Brightness\n",
    "                \n",
    "                outputs_list.append(model(aug_images))  # Predict on augmented images\n",
    "            \n",
    "            # Average predictions\n",
    "            avg_outputs = torch.mean(torch.stack(outputs_list), dim=0)\n",
    "            _, predicted = torch.max(avg_outputs, 1)\n",
    "            \n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy with TTA: {accuracy:.2f}%\")\n",
    "\n",
    "# Run Test-Time Augmentation Evaluation\n",
    "evaluate_tta(swa_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Model Ensembling: 97.87%\n"
     ]
    }
   ],
   "source": [
    "# Ensemble multiple models to boost accuracy\n",
    "def evaluate_ensemble(models, test_loader):\n",
    "    for model in models:\n",
    "        model.eval()  # Set all models to evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs_list = []\n",
    "            for model in models:\n",
    "                outputs_list.append(model(images))  # Get predictions from each model\n",
    "\n",
    "            # Average predictions across models\n",
    "            avg_outputs = torch.mean(torch.stack(outputs_list), dim=0)\n",
    "            _, predicted = torch.max(avg_outputs, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy with Model Ensembling: {accuracy:.2f}%\")\n",
    "\n",
    "# List of models for ensembling\n",
    "models = [swa_model, model]  # Add multiple trained models if available\n",
    "\n",
    "# Run Model Ensembling Evaluation\n",
    "evaluate_ensemble(models, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet18' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m alpha \u001b[38;5;241m*\u001b[39m soft_loss \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m hard_loss\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define Lightweight Student Model (Smaller ResNet18)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m student_model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet18\u001b[49m()\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Define a lightweight version\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Optimizer for Student Model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m optimizer_student \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(student_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNet18' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Define Knowledge Distillation Loss\n",
    "def distillation_loss(student_outputs, teacher_outputs, labels, alpha=0.5, T=3.0):\n",
    "    \"\"\"Compute KD loss: a weighted combination of soft and hard labels\"\"\"\n",
    "    soft_targets = F.softmax(teacher_outputs / T, dim=1)\n",
    "    soft_loss = F.kl_div(F.log_softmax(student_outputs / T, dim=1), soft_targets, reduction=\"batchmean\") * (T * T)\n",
    "    hard_loss = F.cross_entropy(student_outputs, labels)\n",
    "    \n",
    "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
    "\n",
    "# Define Lightweight Student Model (Smaller ResNet18)\n",
    "student_model = ResNet18().to(device)  # Define a lightweight version\n",
    "\n",
    "# Optimizer for Student Model\n",
    "optimizer_student = optim.Adam(student_model.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "\n",
    "# Train Student Model with Knowledge Distillation\n",
    "def train_student(teacher, student, train_loader, criterion, optimizer, epochs=5, alpha=0.5, T=3.0):\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            teacher_outputs = teacher(images).detach()  # Get soft labels from teacher\n",
    "            student_outputs = student(images)\n",
    "\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, alpha, T)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Student Model Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Train Student Model\n",
    "train_student(swa_model, student_model, train_loader, criterion, optimizer_student, epochs=5)\n",
    "\n",
    "# Evaluate the Student Model\n",
    "evaluate(student_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Defined Successfully!\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a lightweight Student Model (Smaller ResNet18)\n",
    "class StudentResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(StudentResNet18, self).__init__()\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)  # Modify output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize the Student Model\n",
    "student_model = StudentResNet18().to(device)\n",
    "\n",
    "print(\"Student Model Defined Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_student' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer_student \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(student_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train Student Model with Knowledge Distillation\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrain_student\u001b[49m(swa_model, student_model, train_loader, criterion, optimizer_student, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the Student Model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m evaluate(student_model, test_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_student' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimizer for Student Model\n",
    "optimizer_student = optim.Adam(student_model.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "\n",
    "# Train Student Model with Knowledge Distillation\n",
    "train_student(swa_model, student_model, train_loader, criterion, optimizer_student, epochs=5)\n",
    "\n",
    "# Evaluate the Student Model\n",
    "evaluate(student_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_student function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Define Knowledge Distillation Loss\n",
    "def distillation_loss(student_outputs, teacher_outputs, labels, alpha=0.5, T=3.0):\n",
    "    \"\"\"Compute KD loss: a weighted combination of soft and hard labels\"\"\"\n",
    "    soft_targets = F.softmax(teacher_outputs / T, dim=1)\n",
    "    soft_loss = F.kl_div(F.log_softmax(student_outputs / T, dim=1), soft_targets, reduction=\"batchmean\") * (T * T)\n",
    "    hard_loss = F.cross_entropy(student_outputs, labels)\n",
    "    \n",
    "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
    "\n",
    "# Train Student Model with Knowledge Distillation\n",
    "def train_student(teacher, student, train_loader, criterion, optimizer, epochs=5, alpha=0.5, T=3.0):\n",
    "    teacher.eval()  # Set teacher model to evaluation mode\n",
    "    student.train()  # Set student model to training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            teacher_outputs = teacher(images).detach()  # Get soft labels from teacher\n",
    "            student_outputs = student(images)\n",
    "\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, alpha, T)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Student Model Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "print(\"train_student function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:43<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Epoch [1/5], Loss: 34.1534, Accuracy: 74.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:41<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Epoch [2/5], Loss: 10.5181, Accuracy: 90.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:41<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Epoch [3/5], Loss: 8.0068, Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:41<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Epoch [4/5], Loss: 6.9160, Accuracy: 93.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:41<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Epoch [5/5], Loss: 6.2843, Accuracy: 95.07%\n",
      "Test Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "# Optimizer for Student Model\n",
    "optimizer_student = optim.Adam(student_model.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "\n",
    "# Train Student Model with Knowledge Distillation\n",
    "train_student(swa_model, student_model, train_loader, criterion, optimizer_student, epochs=5)\n",
    "\n",
    "# Evaluate the Student Model\n",
    "evaluate(student_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:45<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 4.5078, Accuracy: 93.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:43<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 4.4932, Accuracy: 93.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:53<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 4.3564, Accuracy: 93.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:45<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 4.6878, Accuracy: 91.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:04<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 4.5660, Accuracy: 93.23%\n",
      "Test Accuracy: 97.60%\n"
     ]
    }
   ],
   "source": [
    "# Reduce Learning Rate for Final Fine-Tuning\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = 0.0001  # Lower LR for fine-tuning\n",
    "\n",
    "# Fine-Tune SWA Model for 5 More Epochs\n",
    "train(swa_model, train_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "# Evaluate SWA Model Again\n",
    "evaluate(swa_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models list defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define multiple trained models for ensembling\n",
    "models = [swa_model, student_model]  # Add both teacher and student models\n",
    "\n",
    "print(\"✅ Models list defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Model Ensembling: 97.07%\n"
     ]
    }
   ],
   "source": [
    "evaluate_ensemble(models, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "               Impeller (3.0BAR)       1.00      1.00      1.00        91\n",
      "     Mechanical Seal Hole (3BAR)       0.98      0.93      0.95        94\n",
      "Mechanical Seal Scratch (3.0BAR)       0.93      0.99      0.96        95\n",
      "                   Normal (3BAR)       1.00      0.99      0.99        95\n",
      "\n",
      "                        accuracy                           0.98       375\n",
      "                       macro avg       0.98      0.98      0.98       375\n",
      "                    weighted avg       0.98      0.98      0.98       375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def generate_classification_report(model, test_loader, class_names):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    print(\"🔹 Classification Report:\\n\", report)\n",
    "\n",
    "# Define Class Labels\n",
    "class_names = [\"Impeller (3.0BAR)\", \"Mechanical Seal Hole (3BAR)\", \"Mechanical Seal Scratch (3.0BAR)\", \"Normal (3BAR)\"]\n",
    "\n",
    "# Generate Report\n",
    "generate_classification_report(swa_model, test_loader, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(model, test_loader, class_names):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plot_confusion_matrix(swa_model, test_loader, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
