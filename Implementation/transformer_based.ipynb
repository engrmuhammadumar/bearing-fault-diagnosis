{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ==== 1. CONFIGURATION ====\n",
    "data_dir = r\"E:\\Collaboration Work\\With Farooq\\Bearings MDPI\\CWT_Log\\For Channel-02\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "num_classes = 4  # Inner, Outer, Roller, Normal\n",
    "img_size = 128\n",
    "patch_size = 16\n",
    "\n",
    "# ==== 2. TRANSFORMS & DATA LOADING ====\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "class_names = dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ==== 3. TRANSFORMER MODEL ====\n",
    "class SimpleViT(nn.Module):\n",
    "    def __init__(self, img_size, patch_size, num_classes, dim=128, depth=6, heads=8, mlp_dim=256):\n",
    "        super().__init__()\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "        patch_dim = patch_size * patch_size\n",
    "\n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        self.linear_proj = nn.Linear(patch_dim, dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.unfold(x).transpose(1, 2)  # Shape: (B, num_patches, patch_dim)\n",
    "        x = self.linear_proj(x)  # Shape: (B, num_patches, dim)\n",
    "        cls_token = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = x + self.pos_embedding[:, :x.size(1)]\n",
    "        x = self.transformer(x)\n",
    "        return self.mlp_head(x[:, 0])\n",
    "\n",
    "model = SimpleViT(img_size=img_size, patch_size=patch_size, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ==== 4. TRAINING LOOP ====\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ==== 5. EVALUATION ====\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"Validation Accuracy: {acc * 100:.2f}%\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef673339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ==== Configuration ====\n",
    "data_dir = r\"E:\\Collaboration Work\\With Farooq\\Bearings MDPI\\CWT_Log\\For Channel-02\"\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "learning_rate = 0.0001\n",
    "img_size = 224\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Transforms ====\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# ==== Load full dataset ====\n",
    "full_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "\n",
    "# ==== Stratified Split ====\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, val_idx in splitter.split(torch.zeros(len(targets)), targets):\n",
    "    train_dataset = Subset(full_dataset, train_idx)\n",
    "    val_dataset = Subset(full_dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"✅ Classes: {full_dataset.classes}\")\n",
    "\n",
    "# ==== Vision Transformer ====\n",
    "model = models.vit_b_16(pretrained=True)\n",
    "in_features = model.heads[0].in_features\n",
    "model.heads = nn.Sequential(nn.Linear(in_features, len(full_dataset.classes)))\n",
    "model = model.to(device)\n",
    "\n",
    "# ==== Loss, Optimizer, Scheduler ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# ==== Training Function ====\n",
    "def train_model():\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ==== Evaluation Function ====\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"\\n✅ Final Validation Accuracy: {acc * 100:.2f}%\")\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=full_dataset.classes))\n",
    "\n",
    "# ==== Run ====\n",
    "train_model()\n",
    "evaluate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ==== Extract Features for t-SNE and Confusion Matrix ====\n",
    "model.eval()\n",
    "all_features = []\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Extract penultimate features\n",
    "        features = model._modules['heads'][0].in_features\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Get embeddings from penultimate layer\n",
    "        hook_output = []\n",
    "        def hook(module, input, output):\n",
    "            hook_output.append(output.cpu().numpy())\n",
    "        \n",
    "        handle = model.heads[0].register_forward_hook(hook)\n",
    "        _ = model(images)\n",
    "        handle.remove()\n",
    "        embeddings = hook_output[0]\n",
    "        \n",
    "        all_features.append(embeddings)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# ==== Prepare Data ====\n",
    "features_np = np.concatenate(all_features, axis=0)\n",
    "labels_np = np.array(all_labels)\n",
    "\n",
    "# ==== t-SNE Plot ====\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "features_tsne = tsne.fit_transform(features_np)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "palette = sns.color_palette(\"hls\", len(full_dataset.classes))\n",
    "sns.scatterplot(x=features_tsne[:, 0], y=features_tsne[:, 1], hue=labels_np, palette=palette, legend='full', alpha=0.7)\n",
    "plt.title(\"t-SNE Visualization of Extracted Features\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Dimension 1\", fontsize=12)\n",
    "plt.ylabel(\"Dimension 2\", fontsize=12)\n",
    "plt.legend(title=\"Class\", labels=full_dataset.classes)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==== Confusion Matrix ====\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=full_dataset.classes)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap=\"Blues\", colorbar=True)\n",
    "plt.title(\"Confusion Matrix\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "palette = sns.color_palette(\"hls\", len(full_dataset.classes))\n",
    "sns.scatterplot(x=features_tsne[:, 0], y=features_tsne[:, 1], hue=labels_np, palette=palette, legend='full', alpha=0.7)\n",
    "#lt.title(\"t-SNE Visualization of Extracted Features\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Dimension 1\", fontsize=12)\n",
    "plt.ylabel(\"Dimension 2\", fontsize=12)\n",
    "plt.legend(title=\"Class\", labels=full_dataset.classes)\n",
    "#plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51a316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
